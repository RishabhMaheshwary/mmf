(window.webpackJsonp=window.webpackJsonp||[]).push([[17],{107:function(e,t,n){"use strict";n.d(t,"a",(function(){return b})),n.d(t,"b",(function(){return m}));var a=n(0),r=n.n(a);function i(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function o(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);t&&(a=a.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,a)}return n}function c(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?o(Object(n),!0).forEach((function(t){i(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):o(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function l(e,t){if(null==e)return{};var n,a,r=function(e,t){if(null==e)return{};var n,a,r={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(r[n]=e[n]);return r}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(r[n]=e[n])}return r}var d=r.a.createContext({}),p=function(e){var t=r.a.useContext(d),n=t;return e&&(n="function"==typeof e?e(t):c(c({},t),e)),n},b=function(e){var t=p(e.components);return r.a.createElement(d.Provider,{value:t},e.children)},s={inlineCode:"code",wrapper:function(e){var t=e.children;return r.a.createElement(r.a.Fragment,{},t)}},u=r.a.forwardRef((function(e,t){var n=e.components,a=e.mdxType,i=e.originalType,o=e.parentName,d=l(e,["components","mdxType","originalType","parentName"]),b=p(n),u=a,m=b["".concat(o,".").concat(u)]||b[u]||s[u]||i;return n?r.a.createElement(m,c(c({ref:t},d),{},{components:n})):r.a.createElement(m,c({ref:t},d))}));function m(e,t){var n=arguments,a=t&&t.mdxType;if("string"==typeof e||a){var i=n.length,o=new Array(i);o[0]=u;var c={};for(var l in t)hasOwnProperty.call(t,l)&&(c[l]=t[l]);c.originalType=e,c.mdxType="string"==typeof e?e:a,o[1]=c;for(var d=2;d<i;d++)o[d]=n[d];return r.a.createElement.apply(null,o)}return r.a.createElement.apply(null,n)}u.displayName="MDXCreateElement"},87:function(e,t,n){"use strict";n.r(t),n.d(t,"frontMatter",(function(){return o})),n.d(t,"metadata",(function(){return c})),n.d(t,"toc",(function(){return l})),n.d(t,"default",(function(){return p}));var a=n(3),r=n(8),i=(n(0),n(107)),o={id:"butd",sidebar_label:"BUTD",title:"BUTD"},c={unversionedId:"projects/butd",id:"projects/butd",isDocsHomePage:!1,title:"BUTD",description:"This is a tutorial for running the BUTD model available in MMF. This model was released originally under this (repo). Please cite the following paper if you are using BUTD model from mmf:",source:"@site/docs/projects/butd.md",slug:"/projects/butd",permalink:"/docs/projects/butd",editUrl:"https://github.com/facebookresearch/mmf/edit/master/website/docs/projects/butd.md",version:"current",lastUpdatedBy:"Vedanuj Goswami",lastUpdatedAt:1598500718,sidebar_label:"BUTD",sidebar:"docs",previous:{title:"VQA Challenge",permalink:"/docs/challenges/vqa_challenge"},next:{title:"Iterative Answer Prediction with Pointer-Augmented Multimodal Transformers for TextVQA",permalink:"/docs/projects/m4c"}},l=[{value:"Installation",id:"installation",children:[]},{value:"Data Setup",id:"data-setup",children:[]},{value:"Training and Evaluation",id:"training-and-evaluation",children:[]},{value:"Inference Prediction",id:"inference-prediction",children:[]},{value:"Pretrained model",id:"pretrained-model",children:[]}],d={toc:l};function p(e){var t=e.components,n=Object(r.a)(e,["components"]);return Object(i.b)("wrapper",Object(a.a)({},d,n,{components:t,mdxType:"MDXLayout"}),Object(i.b)("p",null,"This is a tutorial for running the BUTD model available in MMF. This model was released originally under this (",Object(i.b)("a",{parentName:"p",href:"https://github.com/peteanderson80/bottom-up-attention"},"repo"),"). Please cite the following paper if you are using BUTD model from mmf:"),Object(i.b)("ul",null,Object(i.b)("li",{parentName:"ul"},"Anderson, P., He, X., Buehler, C., Teney, D., Johnson, M., Gould, S., & Zhang, L. (2018). ",Object(i.b)("em",{parentName:"li"},"Bottom-up and top-down attention for image captioning and visual question answering"),". In Proceedings of the IEEE conference on computer vision and pattern recognition (pp. 6077-6086). (",Object(i.b)("a",{parentName:"li",href:"https://arxiv.org/abs/1707.07998"},"arXiV"),")")),Object(i.b)("pre",null,Object(i.b)("code",{parentName:"pre"},"@inproceedings{Anderson2017up-down,\n  author = {Peter Anderson and Xiaodong He and Chris Buehler and Damien Teney and Mark Johnson and Stephen Gould and Lei Zhang},\n  title = {Bottom-Up and Top-Down Attention for Image Captioning and Visual Question Answering},\n  booktitle={CVPR},\n  year = {2018}\n}\n")),Object(i.b)("h2",{id:"installation"},"Installation"),Object(i.b)("p",null,"Install MMF following the ",Object(i.b)("a",{parentName:"p",href:"https://mmf.sh/docs/getting_started/installation/"},"installation guide"),"."),Object(i.b)("h2",{id:"data-setup"},"Data Setup"),Object(i.b)("p",null,"For training the BUTD model on COCO captions we use the Karpathy splits. Annotations and features for COCO will be automatically downloaded."),Object(i.b)("h2",{id:"training-and-evaluation"},"Training and Evaluation"),Object(i.b)("p",null,"To train BUTD model on the COCO karpathy train split, run:"),Object(i.b)("pre",null,Object(i.b)("code",{parentName:"pre",className:"language-bash"},"mmf_run config=projects/butd/configs/coco/defaults.yaml \\\n    model=butd \\\n    dataset=coco \\\n    run_type=train\n")),Object(i.b)("p",null,"this will save the trained model ",Object(i.b)("inlineCode",{parentName:"p"},"butd_final.pth")," in your ",Object(i.b)("inlineCode",{parentName:"p"},"./save")," directory for the experiment."),Object(i.b)("p",null,"To evaluate the trained model on the COCO val set, run:"),Object(i.b)("pre",null,Object(i.b)("code",{parentName:"pre",className:"language-bash"},"mmf_run config=projects/butd/configs/coco/defaults.yaml \\\n    model=butd \\\n    dataset=coco \\\n    run_type=val \\\n    checkpoint.resume_file=<path_to_trained_pth_file>\n")),Object(i.b)("p",null,"BUTD evaluation can also be done with two other decoding variants with the same trained model, Beam Search and Nucleus Sampling. The following configs can be used :"),Object(i.b)("ul",null,Object(i.b)("li",{parentName:"ul"},"Beam Search Decoding (",Object(i.b)("inlineCode",{parentName:"li"},"projects/butd/configs/coco/beam_search.yaml"),")"),Object(i.b)("li",{parentName:"ul"},"Nucleus Sampling Decoding (",Object(i.b)("inlineCode",{parentName:"li"},"projects/butd/configs/coco/nucleus_sampling.yaml"),")")),Object(i.b)("pre",null,Object(i.b)("code",{parentName:"pre",className:"language-bash"},"mmf_run config=projects/butd/configs/coco/beam_search.yaml \\\n    model=butd \\\n    dataset=coco \\\n    run_type=val \\\n    checkpoint.resume_file=<path_to_trained_pth_file>\n")),Object(i.b)("h2",{id:"inference-prediction"},"Inference Prediction"),Object(i.b)("p",null,"To generate the coco captions prediction file for Karpathy ",Object(i.b)("inlineCode",{parentName:"p"},"val")," or ",Object(i.b)("inlineCode",{parentName:"p"},"test")," splits, run:"),Object(i.b)("pre",null,Object(i.b)("code",{parentName:"pre",className:"language-bash"},"mmf_predict config=projects/butd/configs/coco/beam_search.yaml \\\n    model=butd \\\n    dataset=coco \\\n    run_type=val \\\n    checkpoint.resume_file=<path_to_trained_pth_file>\n")),Object(i.b)("div",{className:"admonition admonition-note alert alert--secondary"},Object(i.b)("div",{parentName:"div",className:"admonition-heading"},Object(i.b)("h5",{parentName:"div"},Object(i.b)("span",{parentName:"h5",className:"admonition-icon"},Object(i.b)("svg",{parentName:"span",xmlns:"http://www.w3.org/2000/svg",width:"14",height:"16",viewBox:"0 0 14 16"},Object(i.b)("path",{parentName:"svg",fillRule:"evenodd",d:"M6.3 5.69a.942.942 0 0 1-.28-.7c0-.28.09-.52.28-.7.19-.18.42-.28.7-.28.28 0 .52.09.7.28.18.19.28.42.28.7 0 .28-.09.52-.28.7a1 1 0 0 1-.7.3c-.28 0-.52-.11-.7-.3zM8 7.99c-.02-.25-.11-.48-.31-.69-.2-.19-.42-.3-.69-.31H6c-.27.02-.48.13-.69.31-.2.2-.3.44-.31.69h1v3c.02.27.11.5.31.69.2.2.42.31.69.31h1c.27 0 .48-.11.69-.31.2-.19.3-.42.31-.69H8V7.98v.01zM7 2.3c-3.14 0-5.7 2.54-5.7 5.68 0 3.14 2.56 5.7 5.7 5.7s5.7-2.55 5.7-5.7c0-3.15-2.56-5.69-5.7-5.69v.01zM7 .98c3.86 0 7 3.14 7 7s-3.14 7-7 7-7-3.12-7-7 3.14-7 7-7z"}))),"note")),Object(i.b)("div",{parentName:"div",className:"admonition-content"},Object(i.b)("p",{parentName:"div"},"Evaluation predictions can only be generated using either ",Object(i.b)("inlineCode",{parentName:"p"},"beam_search")," or ",Object(i.b)("inlineCode",{parentName:"p"},"nucleus_sampling")," methods."))),Object(i.b)("h2",{id:"pretrained-model"},"Pretrained model"),Object(i.b)("table",null,Object(i.b)("thead",{parentName:"table"},Object(i.b)("tr",{parentName:"thead"},Object(i.b)("th",{parentName:"tr",align:null},"Datasets"),Object(i.b)("th",{parentName:"tr",align:null},"Config File"),Object(i.b)("th",{parentName:"tr",align:null},"Pretrained Model Key"),Object(i.b)("th",{parentName:"tr",align:null},"Metrics"),Object(i.b)("th",{parentName:"tr",align:null}))),Object(i.b)("tbody",{parentName:"table"},Object(i.b)("tr",{parentName:"tbody"},Object(i.b)("td",{parentName:"tr",align:null},"COCO (",Object(i.b)("inlineCode",{parentName:"td"},"coco"),")"),Object(i.b)("td",{parentName:"tr",align:null},Object(i.b)("inlineCode",{parentName:"td"},"projects/butd/configs/coco/beam_search.yaml")),Object(i.b)("td",{parentName:"tr",align:null},Object(i.b)("inlineCode",{parentName:"td"},"butd")),Object(i.b)("td",{parentName:"tr",align:null},"val accuracy - 0.36 BLEU4"),Object(i.b)("td",{parentName:"tr",align:null})))),Object(i.b)("p",null,"To generate predictions with the pretrained BUTD model on COCO Karpathy ",Object(i.b)("inlineCode",{parentName:"p"},"val")," set (assuming that the pretrained model that you are evaluating is ",Object(i.b)("inlineCode",{parentName:"p"},"butd"),"), run:"),Object(i.b)("pre",null,Object(i.b)("code",{parentName:"pre",className:"language-bash"},"mmf_predict config=projects/butd/configs/coco/beam_search.yaml \\\n    model=butd \\\n    dataset=coco \\\n    run_type=val \\\n    checkpoint.resume_zoo=butd\n")),Object(i.b)("div",{className:"admonition admonition-tip alert alert--success"},Object(i.b)("div",{parentName:"div",className:"admonition-heading"},Object(i.b)("h5",{parentName:"div"},Object(i.b)("span",{parentName:"h5",className:"admonition-icon"},Object(i.b)("svg",{parentName:"span",xmlns:"http://www.w3.org/2000/svg",width:"12",height:"16",viewBox:"0 0 12 16"},Object(i.b)("path",{parentName:"svg",fillRule:"evenodd",d:"M6.5 0C3.48 0 1 2.19 1 5c0 .92.55 2.25 1 3 1.34 2.25 1.78 2.78 2 4v1h5v-1c.22-1.22.66-1.75 2-4 .45-.75 1-2.08 1-3 0-2.81-2.48-5-5.5-5zm3.64 7.48c-.25.44-.47.8-.67 1.11-.86 1.41-1.25 2.06-1.45 3.23-.02.05-.02.11-.02.17H5c0-.06 0-.13-.02-.17-.2-1.17-.59-1.83-1.45-3.23-.2-.31-.42-.67-.67-1.11C2.44 6.78 2 5.65 2 5c0-2.2 2.02-4 4.5-4 1.22 0 2.36.42 3.22 1.19C10.55 2.94 11 3.94 11 5c0 .66-.44 1.78-.86 2.48zM4 14h5c-.23 1.14-1.3 2-2.5 2s-2.27-.86-2.5-2z"}))),"tip")),Object(i.b)("div",{parentName:"div",className:"admonition-content"},Object(i.b)("p",{parentName:"div"},"Follow ",Object(i.b)("a",{parentName:"p",href:"https://mmf.sh/docs/tutorials/checkpointing"},"checkpointing")," tutorial to understand more fine-grained details of checkpoint, loading and resuming in MMF"))))}p.isMDXComponent=!0}}]);