model_config:
  topdown_vqa: &topdown_vqa
    model_data_dir: ${env.data_dir}
    losses:
    - type: logit_bce
    text_embedding:
      embedding_dim: 300
    lstm:
      input_size: 300
      hidden_size: 512
      bidirectional: false
      batch_first: true
    classifier:
      type: mlp
      params:
        in_dim: 512
        out_dim: 3

dataset_config:
  vizwiz:
      data_dir: ${env.data_dir}/datasets
      depth_first: false
      fast_read: false
      use_images: false
      use_features: true
      zoo_requirements:
      - vizwiz.v2020
      features:
          train:
          - vizwiz2/train_features
          val:
          - vizwiz2/val_features
          test:
          - vizwiz2/val_features
      annotations:
          train:
          - vizwiz2/annotations_classification/imdb_vizwiz_train.npy
          val:
          - vizwiz2/annotations_classification/imdb_vizwiz_val.npy
          test:
          - vizwiz2/annotations_classification/imdb_vizwiz_val.npy
      max_features: 100
      processors:
        text_processor:
          type: vocab
          params:
            max_length: 14
            vocab:
              type: random
              vocab_file: vizwiz2/extras/vocabs/vocabulary_100k.txt
            preprocessor:
              type: simple_sentence
              params: {}
        answer_processor:
          type: vqa_answer
          params:
            vocab_file: vizwiz2/extras/vocabs/answers_vizwiz_classification.txt
            preprocessor:
              type: simple_word
              params: {}
            num_answers: 10
        context_processor:
          type: fasttext
          params:
            max_length: 50
            model_file: wiki.en.bin
        ocr_token_processor:
          type: simple_word
          params: {}
        bbox_processor:
          type: bbox
          params:
            max_length: 50
      return_features_info: true
      # Return OCR information
      use_ocr: false
      # Return spatial information of OCR tokens if present
      use_ocr_info: false
optimizer:
  type: adam_w
  params:
    lr: 5e-5
    eps: 1e-8

scheduler:
  type: warmup_linear
  params:
    num_warmup_steps: 6000
    num_training_steps: 60000

evaluation:
  metrics:
  - vqa_accuracy

training:
  batch_size: 1
  lr_scheduler: true
  # Don't forget to update schedule_attributes if you update this
  max_updates: 60000
  early_stop:
    criteria: vizwiz/vqa_accuracy
    minimize: false
